So we've been talking sharded charted clusters for a bit now.

And you've heard at least a few times about this concept of even distribution of data.

We know that a good shard key should contribute to how evenly MongoDB can distribute your data across the shards in your cluster.

But how exactly does MongoDB perform that data distribution?

Recall that with sharding, MongoDB splits your sharded collections into chunks of data.

As you insert data into the collection, the number of chunks on any given shard will grow.

The MongoDB balancer identifies which shards have too many chunks and automatically move chunks across shards in the sharded cluster in an attempt to achieve even data distribution.

Currently, the balancer process runs on the primary member of the config server replica set.

In prior versions the Mongo ES was responsible for running the balancer process.

The balancer process checks the chunked distribution of data across the sharded cluster and looks for certain migration thresholds.

If it detects that there is an imbalance, it starts a balancer round.

The balancer can migrate chunks in parallel.

A given shard cannot participate in more than one migration at a time.

So take the floor of n divided by 2, where n is the number of shards, and you have the number of chunks that can be migrated in a balancer round.

With this cluster, I've got three shards, so I can migrate-- at most-- one chunk at a time.

If we had four shards, the balancer could migrate up to two chunks at a time.

So we're going to need a second round to completely balance this cluster.

These rounds happen consecutively until the balancer process detects that the cluster is as evenly distributed as possible.

Typically, the Mongo ES handles initiating a chunk split.

But the balancer is fully capable of performing splits.

It will do so if it detects chunks that need to be split or as a part of defining chunk ranges for zone sharding.

Now, zones are out of scope for this lesson.

So just remember that the balancer can split chunks if needed.

Now, there is a performance impact of migrating chunks.

The balancer already has behavior built in to minimize workload disruption, such as the one chunk per shard limitation.

To that end, MongoDB surfaces a number of methods for controlling the behavior of the balancer.

You can start or stop the balancer at any time.

If you stop the balancer in the middle of a round, then the balancer stops only after that balancing round completes.

sh.startBalancer and stopBalancer allow you to set a time limit timeout value for how long to wait to stop or start the balancer.

The interval defines how long the client should wait before checking the balancer status again.

Set balancer state just takes a boolean and is either on or off.

There is also a process for scheduling a time window for when this sharded cluster balancer can run.

It does require modifying the config database, which is out of scope for this course.

But we'll link to the tutorial below if you'd like to read up on it for yourself.

To summarize, the sharded cluster balancer is responsible for evenly distributing chunks of data across your sharded cluster.

Starting with MongoDB 3.4, the balancer runs on the Primary member of the config server replica set.

And the balancer process is completely automated and requires minimal user input or guidance.

There are methods for controlling it, however.