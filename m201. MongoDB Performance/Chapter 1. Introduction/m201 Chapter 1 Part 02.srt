
1
00:00:00.000 --> 00:00:01.100


2
00:00:01.100 --> 00:00:05.050
But do not forget that not
all writes and read operations

3
00:00:05.050 --> 00:00:08.690
are non-locking operations.

4
00:00:08.690 --> 00:00:12.590
Writing constantly
to the same document,

5
00:00:12.590 --> 00:00:16.400
for example, and in
similar place updates

6
00:00:16.400 --> 00:00:21.080
will require each write
to block all other writes

7
00:00:21.080 --> 00:00:25.220
on that same document to comply.

8
00:00:25.220 --> 00:00:30.200
In situations such as
this, multiple CPU's do not

9
00:00:30.200 --> 00:00:31.460
help performance.

10
00:00:31.460 --> 00:00:35.110
Because the threads can not
do their work in parallel.

11
00:00:35.110 --> 00:00:37.370
Since always the
same document will

12
00:00:37.370 --> 00:00:40.820
be affected by the same write.

13
00:00:40.820 --> 00:00:44.420
As you probably already
noticed, MongoDB is a database.

14
00:00:44.420 --> 00:00:46.940
And one of the things
expected from databases

15
00:00:46.940 --> 00:00:50.350
is their ability to persist
information written.

16
00:00:50.350 --> 00:00:52.550
Genius we may say.

17
00:00:52.550 --> 00:00:57.090
For persisting data,
MongoDB will use disks.

18
00:00:57.090 --> 00:01:01.130
The IOPS, which stands for input
output operations per second,

19
00:01:01.130 --> 00:01:04.069
that your server DISK
provides, the faster

20
00:01:04.069 --> 00:01:07.160
we can write and read data.

21
00:01:07.160 --> 00:01:09.440
And the faster your
persistency layer

22
00:01:09.440 --> 00:01:13.090
will respond to database
and application requests.

23
00:01:13.090 --> 00:01:17.690
The types of disks will greatly
affect the overall performance

24
00:01:17.690 --> 00:01:20.540
of your MongoDB deployment.

25
00:01:20.540 --> 00:01:24.080
If we compare the
different types of disks.

26
00:01:24.080 --> 00:01:31.100
HDDs, SSDs, EBS, volumes, in
terms of random access latency

27
00:01:31.100 --> 00:01:33.980
and IOPS, we can
immediately tell

28
00:01:33.980 --> 00:01:37.700
that there is going to be a big
difference between what one can

29
00:01:37.700 --> 00:01:40.250
expect, in terms of
performance, given

30
00:01:40.250 --> 00:01:44.660
the different types of disks
that we might be using.

31
00:01:44.660 --> 00:01:49.280
This can be used in
different architectures.

32
00:01:49.280 --> 00:01:52.520
More specifically, we can
use RAID architectures

33
00:01:52.520 --> 00:01:58.340
in our servers for redundancy
of read and write operations.

34
00:01:58.340 --> 00:02:03.890
MongoDB will benefit from some
but not all RAID architectures.

35
00:02:03.890 --> 00:02:05.570
The recommended
RAID architecture

36
00:02:05.570 --> 00:02:10.759
for MongoDB deployments
is RAID 10, or RAID 1- 0.

37
00:02:10.759 --> 00:02:12.530
This architecture
is the one that

38
00:02:12.530 --> 00:02:14.810
offers more redundancy
and safeguards

39
00:02:14.810 --> 00:02:18.890
guarantees with a good
performance combination.

40
00:02:18.890 --> 00:02:22.130
On the other hand, we highly
discourage deployments

41
00:02:22.130 --> 00:02:26.990
that use RAID 5, or even RAID 6.

42
00:02:26.990 --> 00:02:30.950
Since these do not typically
provide sufficient performance

43
00:02:30.950 --> 00:02:33.470
to MongoDB deployments.

44
00:02:33.470 --> 00:02:35.900
We also recommend
avoiding RAID 0.

45
00:02:35.900 --> 00:02:39.680
Because while providing
good write performance,

46
00:02:39.680 --> 00:02:42.020
it provides very
limited availability.

47
00:02:42.020 --> 00:02:46.550
It can lead to reduced
performance on read operations.

48
00:02:46.550 --> 00:02:48.860
Britain is a disk
architecture that

49
00:02:48.860 --> 00:02:51.320
provides both
redundancy of segments

50
00:02:51.320 --> 00:02:53.050
across physical drives.

51
00:02:53.050 --> 00:02:55.970
But also allows
extended performance,

52
00:02:55.970 --> 00:02:57.770
since it last
penalization of multiple

53
00:02:57.770 --> 00:03:01.790
writes, reads, and
reads and writes.

54
00:03:01.790 --> 00:03:04.910
In the same disk
allocated segments.

55
00:03:04.910 --> 00:03:08.840
Which is quite awesome for
a database like MongoDB.

56
00:03:08.840 --> 00:03:10.610
A particularly important
aspect of MongoDB

57
00:03:10.610 --> 00:03:14.240
is the ability to use
several different disks.

58
00:03:14.240 --> 00:03:17.690
That might be available
in your servers.

59
00:03:17.690 --> 00:03:22.190
This will allow to distributing
IO load of different databases,

60
00:03:22.190 --> 00:03:26.540
indexes, journaling, and
other files like lock files.

61
00:03:26.540 --> 00:03:31.930
Which allow you to optimize your
MongoDB overall performance.

62
00:03:31.930 --> 00:03:35.850
MongoDB deployments also
rely on network hardware.

63
00:03:35.850 --> 00:03:37.560
Applications will
reach the database

64
00:03:37.560 --> 00:03:41.190
by establishing connections
to the hosts, where

65
00:03:41.190 --> 00:03:44.415
MongoDB instance is running.

66
00:03:44.415 --> 00:03:48.630
The faster and the
larger the bandwidth

67
00:03:48.630 --> 00:03:51.540
is for your network,
the better performance

68
00:03:51.540 --> 00:03:53.610
you will experience.

69
00:03:53.610 --> 00:03:56.910
But this is not the end of
the story regarding network

70
00:03:56.910 --> 00:03:58.780
utilization with MongoDB.

71
00:03:58.780 --> 00:04:02.400
MongoDB is a distributed
database for high availability.

72
00:04:02.400 --> 00:04:06.540
Rapid [INAUDIBLE] clusters do
the high availability part.

73
00:04:06.540 --> 00:04:10.830
But also for horizontal scaling,
where the shard and cluster in

74
00:04:10.830 --> 00:04:13.020
all its different
components, allows

75
00:04:13.020 --> 00:04:17.370
you to get a horizontal
distribution of your data.

76
00:04:17.370 --> 00:04:20.279
The way that your
different hosts

77
00:04:20.279 --> 00:04:24.210
that hold the different nodes
of your cluster are connected,

78
00:04:24.210 --> 00:04:27.780
can affect the overall
performance of your system.

79
00:04:27.780 --> 00:04:32.220
Also, the types of network
switches, load balancers,

80
00:04:32.220 --> 00:04:37.680
firewalls, and how far apart
the cluster nodes are--

81
00:04:37.680 --> 00:04:40.500
either by being distributed
across different data centers

82
00:04:40.500 --> 00:04:41.790
or regions.

83
00:04:41.790 --> 00:04:44.460
The type of connections
between data centers,

84
00:04:44.460 --> 00:04:46.110
especially latency--

85
00:04:46.110 --> 00:04:50.280
we haven't cracked going faster
than the speed of light yet--

86
00:04:50.280 --> 00:04:53.880
will play a great deal in
the performance experienced

87
00:04:53.880 --> 00:04:56.670
by your application.

88
00:04:56.670 --> 00:04:59.160
This aligned with
the write concern,

89
00:04:59.160 --> 00:05:01.320
read concern, and
read preference

90
00:05:01.320 --> 00:05:06.720
that your application can
set while emitting commands

91
00:05:06.720 --> 00:05:10.500
or doing requests
to the server, needs

92
00:05:10.500 --> 00:05:13.590
to be taken into
consideration when

93
00:05:13.590 --> 00:05:17.990
analyzing the performance
of your application.