
1
00:00:00.000 --> 00:00:00.710


2
00:00:00.710 --> 00:00:03.430
In this lesson, we'll
be looking into ways

3
00:00:03.430 --> 00:00:07.900
that you, wearing the system
administrator or DB hat,

4
00:00:07.900 --> 00:00:14.770
has to identify potential impact
of client application changes.

5
00:00:14.770 --> 00:00:18.250
We'll be looking into keeping
track of historical monitoring

6
00:00:18.250 --> 00:00:20.500
data, why is that important.

7
00:00:20.500 --> 00:00:23.247
We'll be looking to a couple
of different spikes in terms

8
00:00:23.247 --> 00:00:25.330
of graphical information
that we should look into,

9
00:00:25.330 --> 00:00:28.540
like watching out for spikes
and connections and spikes

10
00:00:28.540 --> 00:00:32.320
in ops per seconds and
some other few indicators

11
00:00:32.320 --> 00:00:33.910
for a couple of
different examples

12
00:00:33.910 --> 00:00:37.030
that we have prepared for
you, and obviously, spotting

13
00:00:37.030 --> 00:00:39.780
long-lasting
non-indexed question.

14
00:00:39.780 --> 00:00:43.690
This is specifically interesting
from a slow query or slowness

15
00:00:43.690 --> 00:00:45.800
analysis of our system.

16
00:00:45.800 --> 00:00:50.560
But you, if you're wearing the
DB hats or system administrator

17
00:00:50.560 --> 00:00:53.170
hats, you might
say, why do I need

18
00:00:53.170 --> 00:00:55.450
to care about what
developers are doing?

19
00:00:55.450 --> 00:00:57.160
Well, let's face it.

20
00:00:57.160 --> 00:01:00.550
Any of this information
will allow us as DBAs

21
00:01:00.550 --> 00:01:02.620
to sleep better at nights.

22
00:01:02.620 --> 00:01:04.810
That new super-hot
feature that will

23
00:01:04.810 --> 00:01:07.790
generate thousands of
instructions per second

24
00:01:07.790 --> 00:01:11.440
and make everyone happy
needs to be well-tested

25
00:01:11.440 --> 00:01:14.050
with the expected
load, well-configured

26
00:01:14.050 --> 00:01:18.640
in terms of schema design
and indexes to support it.

27
00:01:18.640 --> 00:01:22.150
So you as a DBA need to
make the necessary steps

28
00:01:22.150 --> 00:01:25.390
to keep your system in
shipshape and Bristol fashion.

29
00:01:25.390 --> 00:01:26.950
Let's start with the basics.

30
00:01:26.950 --> 00:01:29.320
If we want to be able to
pinpoint changes in your code

31
00:01:29.320 --> 00:01:32.140
from our system
infrastructure, we

32
00:01:32.140 --> 00:01:35.150
will need context
and historical data.

33
00:01:35.150 --> 00:01:37.920
Let's see this in action
using MongoDB Atlas.

34
00:01:37.920 --> 00:01:41.690
It will look similar from
Cloud and Ops Manager.

35
00:01:41.690 --> 00:01:46.270
In this account of Atlas, I
have the best of two worlds.

36
00:01:46.270 --> 00:01:48.970
We can deploy machines
with the click

37
00:01:48.970 --> 00:01:51.290
of a button, which is great--

38
00:01:51.290 --> 00:01:55.510
can select our infrastructure
engines and Confirm and Deploy.

39
00:01:55.510 --> 00:01:58.510
But once we deploy it,
we would immediately

40
00:01:58.510 --> 00:02:00.260
get our system monitored.

41
00:02:00.260 --> 00:02:02.230
In this particular
example here, I already

42
00:02:02.230 --> 00:02:05.020
have preloaded a
instance, or in this case,

43
00:02:05.020 --> 00:02:08.020
a replica set called Cluster0.

44
00:02:08.020 --> 00:02:10.060
And from there, I
can go immediately

45
00:02:10.060 --> 00:02:12.100
into the dashboard
of historical data,

46
00:02:12.100 --> 00:02:14.320
of monitored
historical data, and I

47
00:02:14.320 --> 00:02:17.680
can start analyzing what
happened with my system.

48
00:02:17.680 --> 00:02:20.380
Once we have a nice set
of historical information

49
00:02:20.380 --> 00:02:22.270
on the behavior of
our application,

50
00:02:22.270 --> 00:02:25.090
we can start to track
down any changes that

51
00:02:25.090 --> 00:02:27.650
might affect our back end.

52
00:02:27.650 --> 00:02:30.530
And this includes watching
out for spikes, spikes

53
00:02:30.530 --> 00:02:33.490
in connections, spikes in
[INAUDIBLE] per second,

54
00:02:33.490 --> 00:02:38.510
and a few other types of
spikes in our dashboard.

55
00:02:38.510 --> 00:02:42.760
Now, in this example, I have
a few client applications

56
00:02:42.760 --> 00:02:46.180
mimicking the constant
flow of requests.

57
00:02:46.180 --> 00:02:49.000
You can see it from the
number of connections

58
00:02:49.000 --> 00:02:53.290
and a bunch of different metrics
that I'm collecting here.

59
00:02:53.290 --> 00:02:55.090
Just analyzing the
number of connections,

60
00:02:55.090 --> 00:02:57.370
I can see here that
a few things happen.

61
00:02:57.370 --> 00:03:00.430
I had a jump here in
terms of my connections,

62
00:03:00.430 --> 00:03:02.570
and then another
jump on this one.

63
00:03:02.570 --> 00:03:04.450
And then they fall back again.

64
00:03:04.450 --> 00:03:08.620
But if we cross-checked
with the number of documents

65
00:03:08.620 --> 00:03:12.190
and the number of
app counters, well,

66
00:03:12.190 --> 00:03:18.070
looks like the spikes did not
affect that much our system,

67
00:03:18.070 --> 00:03:19.930
or did they?

68
00:03:19.930 --> 00:03:22.150
Well, the question
here is that we need

69
00:03:22.150 --> 00:03:25.300
to analyze all types of spikes.

70
00:03:25.300 --> 00:03:28.060
In this case here, I'm
going to zoom in a region

71
00:03:28.060 --> 00:03:31.360
where I can have information
on all different spikes that

72
00:03:31.360 --> 00:03:32.610
happened here.

73
00:03:32.610 --> 00:03:38.530
In this one here, my up counters
and document metrics, as well,

74
00:03:38.530 --> 00:03:41.350
is skewing up a
little bit my data.

75
00:03:41.350 --> 00:03:43.340
I know exactly
what happened here.

76
00:03:43.340 --> 00:03:46.690
But if you don't, you as
a DBA should immediately

77
00:03:46.690 --> 00:03:50.350
be asking your developers,
what went wrong

78
00:03:50.350 --> 00:03:52.800
on this particular
point in time?

79
00:03:52.800 --> 00:03:54.550
What that is saying,
not what was wrong,

80
00:03:54.550 --> 00:03:57.820
but what did you guys
do at this point?

81
00:03:57.820 --> 00:04:00.760
Now, if I want to correlate that
with the number of connections

82
00:04:00.760 --> 00:04:04.470
established, I need
to select just those--

83
00:04:04.470 --> 00:04:06.220
still getting a little
bit of skewed data.

84
00:04:06.220 --> 00:04:09.640
Let's just remove
that from our view.

85
00:04:09.640 --> 00:04:13.180
And once we do that, we can
see a total different figure.

86
00:04:13.180 --> 00:04:16.579
Raising the number of
connections in my system--

87
00:04:16.579 --> 00:04:22.220
this correlates with a bunch
more work in my application

88
00:04:22.220 --> 00:04:27.880
that was being skewed out
by other spikes in my graph.

89
00:04:27.880 --> 00:04:31.542
So make sure you understand
that not always what we see

90
00:04:31.542 --> 00:04:33.560
is what actually is going on.

91
00:04:33.560 --> 00:04:36.300
So you need to be
careful about that.