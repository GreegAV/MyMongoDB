
1
00:00:00.000 --> 00:00:00.530


2
00:00:00.530 --> 00:00:03.950
I've written an example script
so that you can try this.

3
00:00:03.950 --> 00:00:05.750
What this script
does is it spawns

4
00:00:05.750 --> 00:00:08.390
a bunch of parallel
processes, 20 by default,

5
00:00:08.390 --> 00:00:11.610
and they all try to
write the same document.

6
00:00:11.610 --> 00:00:13.820
Let's create a replica set.

7
00:00:13.820 --> 00:00:16.219
And I'm going to
show a few things to.

8
00:00:16.219 --> 00:00:19.160
So I'm going to open up a few
tabs to do things in parallel.

9
00:00:19.160 --> 00:00:21.944
First, I'm going to start
here with the mongo shell.

10
00:00:21.944 --> 00:00:23.360
I want to capture
some information

11
00:00:23.360 --> 00:00:24.590
about what I'm going to do.

12
00:00:24.590 --> 00:00:28.280
So let's take a snapshot of
the current server status.

13
00:00:28.280 --> 00:00:31.760
Next, let's set up
mongostat in another tab.

14
00:00:31.760 --> 00:00:34.370
I'll connect to just the
server on port 30,000.

15
00:00:34.370 --> 00:00:37.310
And I just want a few fields
to make it look pretty.

16
00:00:37.310 --> 00:00:39.500
Right now, I've got a
few connections just

17
00:00:39.500 --> 00:00:43.340
from the replica set, the
mongo shell, and now mongostat.

18
00:00:43.340 --> 00:00:45.260
And now we're in
a third tab, where

19
00:00:45.260 --> 00:00:47.900
we're going to run our script.

20
00:00:47.900 --> 00:00:49.670
Let's go to mongostat.

21
00:00:49.670 --> 00:00:53.870
First, you'll notice that it
says there are 20 inserts.

22
00:00:53.870 --> 00:00:55.520
It did get 20 insert commands.

23
00:00:55.520 --> 00:00:58.710
But most of them failed with
the duplicate key error.

24
00:00:58.710 --> 00:01:02.010
Next, you can see that we've
got a bunch of updates going on.

25
00:01:02.010 --> 00:01:04.620
And you can see that I'm
dirtying a lot of my cache

26
00:01:04.620 --> 00:01:08.880
quickly all just to update
that one single document.

27
00:01:08.880 --> 00:01:12.020
You can also see that I've
added more than one connection

28
00:01:12.020 --> 00:01:13.010
per process.

29
00:01:13.010 --> 00:01:14.480
There are 20 processes.

30
00:01:14.480 --> 00:01:18.080
And we created 40 connections,
even though each is just

31
00:01:18.080 --> 00:01:20.030
one mongo client.

32
00:01:20.030 --> 00:01:22.520
Each mongo client actually
maintains a connection pool

33
00:01:22.520 --> 00:01:24.230
to the server,
though that's outside

34
00:01:24.230 --> 00:01:27.410
of the scope of this course
to discuss that in detail.

35
00:01:27.410 --> 00:01:29.870
I've added a link to the
[INAUDIBLE] mongo FAQ in case

36
00:01:29.870 --> 00:01:32.515
you're interested in
reading a bit more.

37
00:01:32.515 --> 00:01:33.890
You can also see
that we're doing

38
00:01:33.890 --> 00:01:36.500
a ton of updates, basically
as fast as our system can

39
00:01:36.500 --> 00:01:37.940
handle them.

40
00:01:37.940 --> 00:01:41.510
And once it's finished,
no more writes.

41
00:01:41.510 --> 00:01:44.130
And our connections
are back down.

42
00:01:44.130 --> 00:01:47.580
Going to the mongo shell,
there's our document.

43
00:01:47.580 --> 00:01:50.370


44
00:01:50.370 --> 00:01:54.440
And if I scroll up, we
had 200,000 updates,

45
00:01:54.440 --> 00:01:56.866
10,000 per process.

46
00:01:56.866 --> 00:01:59.240
Also, while we saw that we
were getting a relatively high

47
00:01:59.240 --> 00:02:01.160
throughput if we
looked at mongostat,

48
00:02:01.160 --> 00:02:04.220
we still have some seriously
long-running operations,

49
00:02:04.220 --> 00:02:06.320
which we'll see in the logs.

50
00:02:06.320 --> 00:02:08.139
I can also check the
current server status

51
00:02:08.139 --> 00:02:09.680
to see how many
operations I've done.

52
00:02:09.680 --> 00:02:12.680


53
00:02:12.680 --> 00:02:16.550
There are my 200,000 updates.

54
00:02:16.550 --> 00:02:20.790
There are my 20
attempted inserts.

55
00:02:20.790 --> 00:02:24.350
And there is my one
insert that succeeded.

56
00:02:24.350 --> 00:02:25.550
Let's check out those logs.

57
00:02:25.550 --> 00:02:30.390


58
00:02:30.390 --> 00:02:33.070
Here is my log path--

59
00:02:33.070 --> 00:02:35.840
copy that.

60
00:02:35.840 --> 00:02:38.090
Let's jump to the bottom.

61
00:02:38.090 --> 00:02:40.910
So most recently, I
can see my 20 processes

62
00:02:40.910 --> 00:02:42.320
closing their connections.

63
00:02:42.320 --> 00:02:44.900
But if I scroll
up, here I can see

64
00:02:44.900 --> 00:02:48.530
a bunch of pairs of write
and command entries.

65
00:02:48.530 --> 00:02:51.260
Note that each pair is
for the same connection--

66
00:02:51.260 --> 00:02:53.570
in this case, connection 71.

67
00:02:53.570 --> 00:02:55.320
They're both saying
the same thing.

68
00:02:55.320 --> 00:02:58.070
I've got queries
that took too long.

69
00:02:58.070 --> 00:03:00.590
You can see we've had
41 write conflicts,

70
00:03:00.590 --> 00:03:03.560
and it yielded 41 times.

71
00:03:03.560 --> 00:03:06.380
That's the source
of the problem.

72
00:03:06.380 --> 00:03:07.880
Typically in
circumstances where you

73
00:03:07.880 --> 00:03:09.950
see a lot of write
conflicts, you probably

74
00:03:09.950 --> 00:03:12.590
would want to
revise your schema.

75
00:03:12.590 --> 00:03:15.380
If all those processes were
working on different documents,

76
00:03:15.380 --> 00:03:18.260
things would improve
dramatically.

77
00:03:18.260 --> 00:03:21.740
With that then, let's go back
to our shell and run our script.

78
00:03:21.740 --> 00:03:26.750
I've set this docPerProcess
flag to avoid contention.

79
00:03:26.750 --> 00:03:30.380
And when we go to mongostat,
here we have our inserts--

80
00:03:30.380 --> 00:03:32.300
looks like it
miscounted a little.

81
00:03:32.300 --> 00:03:35.180
We've got our connections.

82
00:03:35.180 --> 00:03:36.541
We've got our updates happening.

83
00:03:36.541 --> 00:03:37.790
Let's wait for this to finish.

84
00:03:37.790 --> 00:03:40.370


85
00:03:40.370 --> 00:03:42.992
Once again, we'll
look at our logs.

86
00:03:42.992 --> 00:03:44.450
Here, if we start
at the top, we've

87
00:03:44.450 --> 00:03:47.060
got our initial log entries.

88
00:03:47.060 --> 00:03:48.500
Following that,
we can see a bunch

89
00:03:48.500 --> 00:03:51.410
of our connections spinning up.

90
00:03:51.410 --> 00:03:54.470
Then we see a bunch of
our connections closing,

91
00:03:54.470 --> 00:03:56.154
and that's it.

92
00:03:56.154 --> 00:03:58.070
We don't see any of those
long-running queries

93
00:03:58.070 --> 00:03:59.300
we saw before.

94
00:03:59.300 --> 00:04:00.860
We've eliminated
the write conflicts

95
00:04:00.860 --> 00:04:02.870
by simulating a change
in our schema from one

96
00:04:02.870 --> 00:04:06.080
with a lot of write
conflicts to one without.

97
00:04:06.080 --> 00:04:07.340
What have we seen?

98
00:04:07.340 --> 00:04:08.870
We've looked into
how you can have

99
00:04:08.870 --> 00:04:10.490
sudden drops in throughput.

100
00:04:10.490 --> 00:04:13.250
We've looked at long-running
queries, index builds,

101
00:04:13.250 --> 00:04:15.350
and server write
contention, all of which

102
00:04:15.350 --> 00:04:17.700
does happen in production.

103
00:04:17.700 --> 00:04:19.630
We've seen how to
investigate the causes--

104
00:04:19.630 --> 00:04:21.380
typically, using the
server logs, but also

105
00:04:21.380 --> 00:04:23.360
with currentOp, the profiler.

106
00:04:23.360 --> 00:04:25.820
And we've talked a bit about
how to fix these issues when

107
00:04:25.820 --> 00:04:28.090
they're identified.